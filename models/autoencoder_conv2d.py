import tensorflow as tf
from tensorflow import keras
import tensorflow.keras.backend as K


class AutoencoderConv2d:
    def __init__(self, freq_bins, time_frames, kernel_size=(5, 5)):
        self.bins = freq_bins
        self.frames = time_frames
        self.summary = dict()
        self.model = None
        self.kernel_size = kernel_size

    def get_model(self, name='autoencoder_spectrogram'):
        """FCN design, autoencoder with concat skip connection"""
        mix_input = keras.Input(shape=(self.bins, self.frames), name='mix')
        reshaped_input = tf.expand_dims(mix_input, axis=3)

        x = keras.layers.Conv2D(4, self.kernel_size, padding='same', activation='relu')(reshaped_input)
        x = keras.layers.LayerNormalization()(x)
        x = keras.layers.Conv2D(8, self.kernel_size, padding='same', activation='relu')(x)
        x = keras.layers.LayerNormalization()(x)
        x = keras.layers.Conv2D(16, self.kernel_size, padding='same', activation='relu')(x)
        x = keras.layers.LayerNormalization()(x)
        x = keras.layers.Conv2D(32, self.kernel_size, padding='same', activation='relu')(x)
        x = keras.layers.LayerNormalization()(x)

        # encoder
        # 1st conv + downsampling + batch normalization
        conv1 = keras.layers.Conv2D(64, self.kernel_size, padding='same', activation='relu')(x)
        downsample1 = keras.layers.Conv2D(64, self.kernel_size, strides=(2, 2), padding='same',
                                          activation='relu', use_bias=False)(conv1)
        norm1 = keras.layers.LayerNormalization()(downsample1)

        # 2nd conv + downsampling + batch normalization
        conv2 = keras.layers.Conv2D(128, self.kernel_size, padding='same', activation='relu')(norm1)
        downsample2 = keras.layers.Conv2D(128, self.kernel_size, strides=(2, 2), padding='same',
                                          activation='relu', use_bias=False)(conv2)
        norm2 = keras.layers.LayerNormalization()(downsample2)

        # 3rd conv + batch normalization
        conv3 = keras.layers.Conv2D(256, self.kernel_size, padding='same', activation='relu', use_bias=False)(norm2)
        norm3 = keras.layers.LayerNormalization()(conv3)

        # decoder
        # 4th conv + upsampling + batch normalization
        upsample1 = keras.layers.UpSampling2D((2, 2))(norm3)
        up1_fixed_shape = keras.layers.Conv2D(128, (2, 1), activation='relu', use_bias=False)(upsample1)
        conv4 = keras.layers.Conv2D(128, self.kernel_size, padding='same', activation='relu')(
            keras.layers.concatenate([conv2, up1_fixed_shape]))
        norm4 = keras.layers.LayerNormalization()(conv4)

        # 5th conv + upsampling + batch normalization
        upsample2 = keras.layers.UpSampling2D((2, 2))(norm4)
        up2_fixed_shape = keras.layers.Conv2D(32, (2, 2), activation='relu', use_bias=False)(upsample2)
        conv5 = keras.layers.Conv2D(64, self.kernel_size, padding='same', activation='relu')(
            keras.layers.concatenate([conv1, up2_fixed_shape]))
        norm5 = keras.layers.LayerNormalization()(conv5)

        # output layers
        x = keras.layers.Conv2D(32, self.kernel_size, padding='same', activation='relu')(norm5)
        x = keras.layers.Conv2D(16, self.kernel_size, padding='same', activation='relu')(x)
        x = keras.layers.Conv2D(8, self.kernel_size, padding='same', activation='relu')(x)
        output = keras.layers.Conv2D(4, self.kernel_size, padding='same', activation='relu')(x)

        # uniformly split channels into 4
        # Lambda layer needs to assign name to the layer
        # so that during training, the outputs of the model will find
        # corresponding train data generated by pre-built tfrecord dataset
        vocals = keras.layers.Lambda(lambda x: x[:, :, :, 0], name='vocals')(output)
        bass = keras.layers.Lambda(lambda x: x[:, :, :, 1], name='bass')(output)
        drums = keras.layers.Lambda(lambda x: x[:, :, :, 2], name='drums')(output)
        other = keras.layers.Lambda(lambda x: x[:, :, :, 3], name='other')(output)

        self.model = keras.Model(inputs=[mix_input], outputs=[
                                 vocals, bass, drums, other], name=name)
        return self.model

    def save_weights(self, path):
        pass

    def load_weights(self, path):
        pass

    def save_model_plot(self, file_name='autoencoder_conv2d_separator.png'):
        if self.model is not None:
            root_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))
            images_dir = os.path.join(root_dir, 'images')
            file_path = os.path.join(images_dir, file_name)
            keras.utils.plot_model(self.model, file_path)
        else:
            raise ValueError(
                "no model has been built yet! call get_model() first!")

    def model_summary(self):
        if self.model is not None:
            trainable_count = np.sum([K.count_params(w)
                                      for w in self.model.trainable_weights])
            non_trainable_count = np.sum(
                [K.count_params(w) for w in self.model.non_trainable_weights])
            self.summary = {
                'total_parameters': trainable_count + non_trainable_count,
                'trainable_parameters': trainable_count,
                'non_trainable_parameters': non_trainable_count}
        else:
            raise ValueError(
                "no model has been built yet! call get_model() first!")

    def __str__(self):
        return self.summary

    __repr__ = __str__
